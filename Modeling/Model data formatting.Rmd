---
title: "Model Data Formatting"
author: "Christina Fossum"
date: "2026-01-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Edited by Christina Fossum 1/19/2026

This script contains the code to format raw FFI data into 'pred' dataframes for TLS modeling

Contents:
- PICO Overstory
- Front country RX & Eagle Cliff Overstory
- Fuels and Burn Severity


## Step 1: Format raw FFI data into 'pred' dataframes

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# PICO + Allenspark OVERSTORY
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1. Run data loading functions
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
library(tidyverse)

# Data Function for loading raw FFI output data
load_headers <- function(directory_path, pattern) {
  list_files <- list.files(path = directory_path, pattern = pattern, full.names = TRUE)
  data_list <- lapply(list_files, function(file) {
    file_data <- read.csv(file) %>% select(1:10) %>% filter(Visited == "True")
    file_data <- file_data %>% mutate(Comment = "")
  })
  return(do.call(rbind, data_list))
}

load_data <- function(directory_path, pattern) {
  list_files <- list.files(path = directory_path, pattern = pattern, full.names = TRUE)
  data_list <- lapply(list_files, function(file) {
    if (file.info(file)$size == 0) return(NULL)
    file_data <- tryCatch({
      read.csv(file, skip = 3) %>% mutate(Comment = "")
    }, error = function(e) {
      message("Error reading file: ", file, " - skipping this file.")
      return(NULL)
    })
    return(file_data)
  })
  do.call(rbind, data_list[!sapply(data_list, is.null)])
}

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 2. Load Data
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Load PICO Tree data
directory_path <- "working_data/PRED_RAW_FFI/PICO/"  
  
trees_df <- load_data(directory_path, "_Trees - Individuals \\(metric\\)\\.csv$")
list <- list.files(path = directory_path, pattern = "_Trees - Individuals \\(metric\\)\\.csv$", full.names = TRUE) 
trees_headers <- lapply(list, function(file) read.csv(file, nrows = 1))
trees_headers <- do.call(rbind, trees_headers)  
trees_df <- left_join(x = trees_df, y = trees_headers, by = c("MacroPlot.Name", "Sample.Event.Date"))

# Delete unneeded rows
trees_df <- trees_df %>% select(-c(1,4,5,7,13,15,16,17,20, 21,22,23:25,  26,27,29:40))
trees_df <- trees_df %>%mutate(TreeBA_ft2 = (pi*(DBH/200)^2)*10.7639, PlotArea_Acres = 0.079) 
trees_df1 <- trees_df

# Load Allenspark Tree data
directory_path <- "working_data/PRED_RAW_FFI/Allenspark/"  
  
trees_df <- load_data(directory_path, "_Trees - Individuals \\(metric\\)\\.csv$")
list <- list.files(path = directory_path, pattern = "_Trees - Individuals \\(metric\\)\\.csv$", full.names = TRUE) 
trees_headers <- lapply(list, function(file) read.csv(file, nrows = 1))
trees_headers <- do.call(rbind, trees_headers)  
trees_df <- left_join(x = trees_df, y = trees_headers, by = c("MacroPlot.Name", "Sample.Event.Date"))

# Delete unneeded rows
trees_df <- trees_df %>% select(-c(1,4,5,7,13,15,16,17,20, 21,22,23:25,  26,27,29:40))
trees_df <- trees_df %>%mutate(TreeBA_ft2 = (pi*(DBH/200)^2)*10.7639, PlotArea_Acres = 0.079) 

#filter out Allenspark post-thin plots (piles will skew)
trees_df <- trees_df %>% filter(!grepl("^2024/09/", Sample.Event.Date))

#combine Allenspark + PICO
trees_df <- rbind(trees_df1, trees_df)

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3. Calculate Pred Metrics
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#1. Height
height <- trees_df %>% filter(!is.na(Height)) %>% group_by(MacroPlot.Name, Sample.Event.Date) %>% 
  summarise(maxHt = max(Height), meanHt = mean(Height), medHt = median(Height), sdHt = sd(Height)) %>% ungroup()

#2. CBH
cbh <- trees_df %>% filter(!is.na(Live.Crown.Base.Ht.)) %>% group_by(MacroPlot.Name, Sample.Event.Date) %>% 
  summarise(maxCBH = max(Live.Crown.Base.Ht.), meanCBH = mean(Live.Crown.Base.Ht.), medCBH = median(Live.Crown.Base.Ht.)) %>% ungroup()

#3. DBH
dbh <- trees_df %>% filter(!is.na(DBH)) %>% group_by(MacroPlot.Name, Sample.Event.Date) %>% 
  summarise(maxDBH = max(DBH), meanDBH = mean(DBH), medDBH = median(DBH)) %>% ungroup()

#4. Live vs. Dead Count
status <- trees_df %>% filter(!is.na(Status))%>% group_by(MacroPlot.Name, Sample.Event.Date, Status) %>% summarise(Count = n()) %>% ungroup() %>% pivot_wider(names_from = Status, values_from = Count)
status[is.na(status)] <- 0

#5. poles
poles <- trees_df %>% filter(!is.na(DBH))%>% mutate(sizeclass = case_when(DBH >= 15 ~ "OS", DBH < 15 ~ "Pole")) %>% group_by(MacroPlot.Name, Sample.Event.Date, sizeclass) %>% summarise(Count = n()) %>% ungroup() %>% pivot_wider(names_from = sizeclass, values_from = Count) 
poles[is.na(poles)] <- 0

#6. Basal Area 
ba <- trees_df %>% filter(!is.na(DBH))%>%group_by(MacroPlot.Name, Sample.Event.Date)%>% summarise(ba_ft2_peracre = sum(TreeBA_ft2)/0.079) %>% ungroup()
liveba <- trees_df %>% filter(Status == "L" )%>% filter(!is.na(DBH)) %>%group_by(MacroPlot.Name, Sample.Event.Date)%>% summarise(LIVE_ba_ft2_peracre = sum(TreeBA_ft2)/0.079) %>% ungroup()
snagba <- trees_df %>% filter(Status == "D" )%>% filter(!is.na(DBH)) %>%group_by(MacroPlot.Name, Sample.Event.Date)%>% summarise(SNAG_ba_ft2_peracre = sum(TreeBA_ft2)/0.079) %>% ungroup()
ba2 <- left_join(ba, liveba)
ba2 <- left_join(ba2, snagba)
ba2[is.na(ba2)] <- 0

#combine
met1 <- left_join(status, poles)
met1 <- left_join(met1, dbh)
met1 <- left_join(met1, cbh)
met1 <- left_join(met1, height)
met1 <- left_join(met1, ba2)

#7. Trees per acre
met1 <- met1 %>% mutate(LTrees_perAcre = L/0.079, DTrees_perAcre = D/0.079, OSTrees_perAcre = OS/0.079, Poles_perAcre = Pole/0.079)

#8. basal area by species
spba <- trees_df %>% filter(!is.na(DBH))%>%group_by(MacroPlot.Name, Sample.Event.Date, Species, Status)%>% summarise(ba_ft2_peracre = sum(TreeBA_ft2)/0.079) %>% ungroup()
spba <- spba %>% pivot_wider(names_from = c(Species, Status), values_from = ba_ft2_peracre)

met1 <- left_join(met1, spba)

#write to .csv
write.csv(met1, "working_data/pred_clean/pred_pico_AP_overstory.csv")


```


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Frontcountry RX & Eagle Cliff & extra TLS pipo Overstory
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1. Run data loading functions
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
library(tidyverse)

# Data Function for loading raw FFI output data
load_headers <- function(directory_path, pattern) {
  list_files <- list.files(path = directory_path, pattern = pattern, full.names = TRUE)
  data_list <- lapply(list_files, function(file) {
    file_data <- read.csv(file) %>% select(1:10) %>% filter(Visited == "True")
    file_data <- file_data %>% mutate(Comment = "")
  })
  return(do.call(rbind, data_list))
}

load_data <- function(directory_path, pattern) {
  list_files <- list.files(path = directory_path, pattern = pattern, full.names = TRUE)
  data_list <- lapply(list_files, function(file) {
    if (file.info(file)$size == 0) return(NULL)
    file_data <- tryCatch({
      read.csv(file, skip = 3) %>% mutate(Comment = "")
    }, error = function(e) {
      message("Error reading file: ", file, " - skipping this file.")
      return(NULL)
    })
    return(file_data)
  })
  do.call(rbind, data_list[!sapply(data_list, is.null)])
}

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 2. Load Data
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Load FFI Tree data
#Fall24 rx
directory_path <- "working_data/PRED_RAW_FFI/Fall24RX/"
trees_df <- load_data(directory_path, "_Trees - Individuals \\(metric\\)\\.csv$")
list <- list.files(path = directory_path, pattern = "_Trees - Individuals \\(metric\\)\\.csv$", full.names = TRUE) 
trees_headers <- lapply(list, function(file) read.csv(file, nrows = 1))
trees_headers <- do.call(rbind, trees_headers)  
trees_df <- left_join(x = trees_df, y = trees_headers, by = c("MacroPlot.Name", "Sample.Event.Date"))
#Fall25 rx
directory_path <-  "working_data/PRED_RAW_FFI/Fall25RX/"  
trees_df2 <- load_data(directory_path, "_Trees - Individuals \\(metric\\)\\.csv$")
list <- list.files(path = directory_path, pattern = "_Trees - Individuals \\(metric\\)\\.csv$", full.names = TRUE) 
trees_headers <- lapply(list, function(file) read.csv(file, nrows = 1))
trees_headers <- do.call(rbind, trees_headers)  
trees_df2 <- left_join(x = trees_df2, y = trees_headers, by = c("MacroPlot.Name", "Sample.Event.Date"))
#Spring25 rx
directory_path <- "working_data/PRED_RAW_FFI/Spring25RX/" 
trees_df3 <- load_data(directory_path, "_Trees - Individuals \\(metric\\)\\.csv$")
list <- list.files(path = directory_path, pattern = "_Trees - Individuals \\(metric\\)\\.csv$", full.names = TRUE) 
trees_headers <- lapply(list, function(file) read.csv(file, nrows = 1))
trees_headers <- do.call(rbind, trees_headers)  
trees_df3 <- left_join(x = trees_df3, y = trees_headers, by = c("MacroPlot.Name", "Sample.Event.Date"))
#Eagle Cliff
directory_path <- "working_data/PRED_RAW_FFI/EagleCliff/"  
trees_df4 <- load_data(directory_path, "_Trees - Individuals \\(metric\\)\\.csv$")
list <- list.files(path = directory_path, pattern = "_Trees - Individuals \\(metric\\)\\.csv$", full.names = TRUE) 
trees_headers <- lapply(list, function(file) read.csv(file, nrows = 1))
trees_headers <- do.call(rbind, trees_headers)  
trees_df4 <- left_join(x = trees_df4, y = trees_headers, by = c("MacroPlot.Name", "Sample.Event.Date"))
#other pipo
directory_path <- "working_data/PRED_RAW_FFI/pipo_tls/"
trees_df5 <- load_data(directory_path, "_Trees - Individuals \\(metric\\)\\.csv$")
list <- list.files(path = directory_path, pattern = "_Trees - Individuals \\(metric\\)\\.csv$", full.names = TRUE) 
trees_headers <- lapply(list, function(file) read.csv(file, nrows = 1))
trees_headers <- do.call(rbind, trees_headers)  
trees_df5 <- left_join(x = trees_df5, y = trees_headers, by = c("MacroPlot.Name", "Sample.Event.Date"))

#Join
trees_df <- do.call("rbind", list(trees_df, trees_df2, trees_df3, trees_df4, trees_df5))

# Delete unneeded rows
trees_df <- trees_df %>% select(-c(1,4,5,7,13,15,16,17,20, 21,22, 26,27,29:40))
trees_df <- trees_df %>%mutate(TreeBA_ft2 = (pi*(DBH/200)^2)*10.7639, PlotArea_Acres = 0.079) 

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3. Calculate Pred Metrics
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#1. Height
height <- trees_df %>% filter(!is.na(Height)) %>% group_by(MacroPlot.Name, Sample.Event.Date) %>% 
  summarise(maxHt = max(Height), meanHt = mean(Height), medHt = median(Height), sdHt = sd(Height)) %>% ungroup()

#2. CBH
cbh <- trees_df %>% filter(!is.na(Live.Crown.Base.Ht.)) %>% group_by(MacroPlot.Name, Sample.Event.Date) %>% 
  summarise(maxCBH = max(Live.Crown.Base.Ht.), meanCBH = mean(Live.Crown.Base.Ht.), medCBH = median(Live.Crown.Base.Ht.)) %>% ungroup()

#3. DBH
dbh <- trees_df %>% filter(!is.na(DBH)) %>% group_by(MacroPlot.Name, Sample.Event.Date) %>% 
  summarise(maxDBH = max(DBH), meanDBH = mean(DBH), medDBH = median(DBH)) %>% ungroup()

#4. Live vs. Dead Count
status <- trees_df %>% filter(!is.na(Status))%>% group_by(MacroPlot.Name, Sample.Event.Date, Status) %>% summarise(Count = n()) %>% ungroup() %>% pivot_wider(names_from = Status, values_from = Count)
status[is.na(status)] <- 0

#5. poles
poles <- trees_df %>% filter(!is.na(DBH))%>% mutate(sizeclass = case_when(DBH >= 15 ~ "OS", DBH < 15 ~ "Pole")) %>% group_by(MacroPlot.Name, Sample.Event.Date, sizeclass) %>% summarise(Count = n()) %>% ungroup() %>% pivot_wider(names_from = sizeclass, values_from = Count) 
poles[is.na(poles)] <- 0

#6. Basal Area 
ba <- trees_df %>% filter(!is.na(DBH))%>%group_by(MacroPlot.Name, Sample.Event.Date)%>% summarise(ba_ft2_peracre = sum(TreeBA_ft2)/0.079) %>% ungroup()
liveba <- trees_df %>% filter(Status == "L" )%>% filter(!is.na(DBH)) %>%group_by(MacroPlot.Name, Sample.Event.Date)%>% summarise(LIVE_ba_ft2_peracre = sum(TreeBA_ft2)/0.079) %>% ungroup()
snagba <- trees_df %>% filter(Status == "D" )%>% filter(!is.na(DBH)) %>%group_by(MacroPlot.Name, Sample.Event.Date)%>% summarise(SNAG_ba_ft2_peracre = sum(TreeBA_ft2)/0.079) %>% ungroup()
ba2 <- left_join(ba, liveba)
ba2 <- left_join(ba2, snagba)
ba2[is.na(ba2)] <- 0

#7. scorch/char
fire <- trees_df %>% filter(!is.na(Char.Ht.)) %>% group_by(MacroPlot.Name, Sample.Event.Date) %>% summarise(MaxCharHt = max(Char.Ht.), MeanCharHt = mean(Char.Ht.), MedCharHt = median(Char.Ht.), MaxScHt = max(Scorch.Ht.), MeanScHt = mean(Scorch.Ht.), MedScHt = median(Scorch.Ht.), MaxScPct = max(Crown.Scorch..), MeanScPct = mean(Crown.Scorch..), MedScPct = median(Crown.Scorch..))

#combine
met1 <- left_join(status, poles)
met1 <- left_join(met1, dbh)
met1 <- left_join(met1, cbh)
met1 <- left_join(met1, height)
met1 <- left_join(met1, ba2)
met1 <- left_join(met1, fire)


#7. Trees per acre
met1 <- met1 %>% mutate(LTrees_perAcre = L/0.079, DTrees_perAcre = D/0.079, OSTrees_perAcre = OS/0.079, Poles_perAcre = Pole/0.079)

#write to .csv
write.csv(met1, "working_data/pred_clean//pred_eastside_overstory2.csv")

```


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Fuels & BS
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}

#EastSide
fuels1 <- read.csv("working_data/PRED_RAW_FFI/EagleCliff/Report_SurfaceFuels_E4.csv", skip = 2)
fuels2 <- read.csv("working_data/PRED_RAW_FFI/Fall24RX/Report_SurfaceFuels_E5.csv", skip = 2)
fuels3 <- read.csv("working_data/PRED_RAW_FFI/Fall25RX/Report_SurfaceFuels_E3.csv", skip = 2)
fuels4 <- read.csv("working_data/PRED_RAW_FFI/Spring25RX/Report_SurfaceFuels_E2.csv", skip = 2)
fuels5 <- read.csv("working_data/PRED_RAW_FFI/pipo_tls/Report_SurfaceFuels_Ef.csv", skip = 2)
fuels6 <- read.csv("working_data/PRED_RAW_FFI/pipo_tls/Report_SurfaceFuels_Ep.csv", skip = 2)
#fuels7 <- read.csv("working_data/PRED_RAW_FFI/pipo_tls/Report_SurfaceFuels_Et.csv", skip = 2)
fuels8 <- read.csv("working_data/PRED_RAW_FFI/pipo_tls/Report_SurfaceFuelsCustomFuelConstants_Er.csv", skip = 2)

#Join
fuels <- do.call("rbind", list(fuels1, fuels2, fuels3, fuels4, fuels5, fuels6))

fuels <- fuels %>% select(-c(2, 8:46, 54))
fuels8 <- fuels8 %>% select(-c(2, 8:46, 54))
fuels <- rbind(fuels, fuels8)
fuels <- fuels %>% mutate(ThoHrWoody = TotalWood - FineWood)

#deleting monitoring statuses that dont have scans 
fuels <- fuels %>% slice(-c(47:58, 59:67, 71:79, 83:92, 96:105, 109, 113, 117, 121, 131:139, 141:149, 151:159, 161:167, 169:178, 181:193, 195:198, 200:207, 209:216, 218:221, 223:227, 229:232, 234:237, 239:241, 243:245, 248:250, 253:256, 259:262))
fuels <- fuels %>% slice(-c(35:46))



write.csv(fuels, "working_data/pred_clean/pred_fuels2.csv")

#PICO/AP
fuels5 <- read.csv("working_data/PRED_RAW_FFI/PICO/Report_SurfaceFuels_E.csv", skip = 2)
fuels6 <- read.csv("working_data/PRED_RAW_FFI/Allenspark/Report_SurfaceFuels_E.csv", skip = 2)



#Join
fuels <- rbind(fuels5, fuels6)
fuels <- fuels %>% select(-c(2, 8:46, 54))
fuels <- fuels %>% mutate(ThoHrWoody = TotalWood - FineWood)
fuels <- fuels %>% slice(-c(45, 47, 49, 51, 53)) #delete post-pile



write.csv(fuels, "working_data/pred_clean/pred_pico_AP_fuels.csv")




#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Burn Severity
bs1 <- read.csv("PRED_RAW_FFI/Fall24RX/Report_PostBurnSeverity3.csv")
bs2 <- read.csv("PRED_RAW_FFI/Fall25RX/Report_PostBurnSeverity2.csv")
bs3 <- read.csv("PRED_RAW_FFI/Spring25RX/Report_PostBurnSeverity.csv")

#Join
bs <- do.call("rbind", list(bs1, bs2, bs3))

bs <- bs %>% select(-2)

write.csv(bs, "pred_clean/pred_burnseverity.csv")

```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## Step 2: Add appropriate intelemon Plot IDs to .csv files you just made

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## Step 3: Format matching 'pred' and 'vars' datasets

1. PICO + allenspark

```{r}

library(tidyverse)

# Load Pred data & Combine
fuels <- read.csv("working_data/pred_clean/pred_pico_AP_fuels.csv")
overstory <- read.csv("working_data/pred_clean/pred_pico_AP_overstory.csv")


fuels <- fuels %>% select(-c(Macroplot, MonStatus))
pred <- left_join(overstory, fuels)
pred <- pred %>% select(-c(2,3))
pred[is.na(pred)] <- 0

# Load Vars data
vars <- read.csv("working_data/VARS data/romo_intelimon2026//merged_metrics.csv")

#Filter/Sort 'vars' based on rows that match the 'pred' data
vars <- vars%>% rename(plot = h_filename)
vars <- left_join(pred, vars, by = "plot")

pred <- vars %>% select(c(1:42)) 
vars <- vars %>% select(c(46:296)) 

write.csv(pred, "pico/pico_ap_pred.csv")
write.csv(vars, "pico/pico_ap_vars.csv")

################################
##Add poles / trees per acre
pred <- read.csv("DATA/ROMO_OS_Structure/pred.csv")
pred <- pred %>% mutate(LTrees_perAcre = L/0.079, DTrees_perAcre = D/0.079, OSTrees_perAcre = OS/0.079, Poles_perAcre = Pole/0.079)
write.csv(pred, "DATA/ROMO_OS_Structure/pred.csv")


pred <- read.csv("DATA/ROMO_OS_Structure/pred.csv") %>% select(-c(1:2))
vars <- read.csv("DATA/ROMO_OS_Structure/vars.csv") %>% select(-1)

```

2. Frontcountry
```{r}
library(tidyverse)


# 1. Fuels
fuels <- read.csv("working_data/pred_clean/pred_fuels2.csv")

fuels <- fuels %>% select(-c(Macroplot, MonStatus)) 


# Load Vars data
vars <- read.csv("working_data/VARS data/romo_intelimon2026/merged_metrics.csv")

#Filter/Sort 'vars' based on rows that match the 'pred' data
vars <- vars%>% select(-c(1:2)) %>% rename(X = h_filename)
vars <- left_join(fuels, vars, by = "X")

pred <- vars %>% select(c(1:13)) %>% slice(-8)
vars <- vars %>% select(c(15:267))%>% slice(-8)

write.csv(pred, "eastside/fuels/pred2.csv")
write.csv(vars, "eastside/fuels/vars2.csv")


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 2. Overstory
pred <- read.csv("working_data/pred_clean/pred_eastside_overstory2.csv")
vars <- read.csv("working_data/VARS data/romo_intelimon2026/merged_metrics.csv")

#Filter/Sort 'vars' based on rows that match the 'pred' data
vars <- vars%>% select(-c(1:2)) %>% rename(X.1 = h_filename)
vars <- left_join(pred, vars, by = "X.1")

pred <- vars %>% select(c(1, 4:34))
vars <- vars %>% select(c(36:288))
vars <- vars %>% slice(-c(2))
vars <- vars %>% slice(-c(2))

write.csv(pred, "eastside/overstory/pred2.csv")
write.csv(vars, "eastside/overstory/vars2.csv")

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 3. Burn
bs <- read.csv("working_data/pred_clean/pred_burnseverity.csv") %>% slice(-c(8:13, 15:16, 18:19, 21)) %>% rename(X.1 = X)
os <- read.csv("working_data/pred_clean/pred_eastside_overstory2.csv")

pred <- full_join(os, bs)
pred <- pred %>% select(-c(2:21, 31:36))
pred <- pred %>% slice(-c(3,6,9,12:14, 17,20, 21, 24, 27, 30:50, 54:55, 59:60, 67))
pred[is.na(pred)] <- 0


vars <- read.csv("working_data/VARS data/romo_intelimon2026/merged_metrics.csv")

#Filter/Sort 'vars' based on rows that match the 'pred' data
vars <- vars%>% select(-c(1:2)) %>% rename(X.1 = h_filename)
vars <- left_join(pred, vars, by = "X.1")

pred <- vars %>% select(c(1:22))  %>% slice(-2)
vars <- vars %>% select(c(24:276)) %>% slice(-2)

write.csv(pred, "eastside/burn/pred2.csv")
write.csv(vars, "eastside/burn/vars2.csv")






```

2B. Burn Fuels Change

```{r}
library(tidyverse)

# Load fuels data
fuels <- read.csv("working_data/pred_clean/pred_fuels.csv")

#Delete reads that aren't pre and post burn
fuels <- fuels %>% slice(-c(1:6, 54:67))
fuels <- fuels %>% filter(MonStatus %in% c("00PRE", "01POST", "02PRE", "03POST"))
fuels <- fuels %>% mutate(Status = case_when(MonStatus %in% c("00PRE", "02PRE") ~ "pre", MonStatus %in% c("01POST", "03POST") ~ "post")) %>% select(-MonStatus)

#pivot wider
df_change <- fuels %>%select(-X) %>%   # drop index column
  pivot_wider(names_from = Status,values_from = c(OneHr, TenHr, HunHr, FineWood, TotalWood,Duff, Litter, TotalAll, DuffDep, LittDep,TotDep, ThoHrWoody) ) %>% mutate(OneHr_change       = OneHr_post - OneHr_pre,TenHr_change       = TenHr_post - TenHr_pre,HunHr_change       = HunHr_post - HunHr_pre,
    FineWood_change    = FineWood_post - FineWood_pre,TotalWood_change   = TotalWood_post - TotalWood_pre,Duff_change        = Duff_post - Duff_pre,
    Litter_change      = Litter_post - Litter_pre,TotalAll_change    = TotalAll_post - TotalAll_pre,DuffDep_change     = DuffDep_post - DuffDep_pre,
    LittDep_change     = LittDep_post - LittDep_pre,TotDep_change      = TotDep_post - TotDep_pre,hoHrWoody_change  = ThoHrWoody_post - ThoHrWoody_pre) %>%
  select(Macroplot, ends_with("_change"))



#Load vars
vars <- read.csv("working_data/VARS data/romo_intelimon2026/merged_metrics.csv")
vars <- vars %>% select(-c(1:2)) %>% rename(X = h_filename)
vars <- left_join(fuels, vars)
vars <- vars %>% select(-c(1, 3:14, 16))
vars_change <- vars %>% pivot_wider(names_from = Status, values_from = where(is.numeric))%>%
  mutate(across(ends_with("_post"),~ .x - get(sub("_post$", "_pre", cur_column())), .names = "{sub('_post$', '', .col)}_change")) %>%
  select(Macroplot, ends_with("_change"))
vars_change <- vars_change %>% slice(-c(1:2))
vars_change <- vars_change %>% select(-1)

df_change <- df_change %>% slice(-1) %>% mutate(plot = c("CORMP_0012", "CORMP_0014", "CORMP_0015", "CORMP_0009", "CORMP_0010", "CORMP_0008", "CORMP_0052", "CORMP_0051", "CORMP_0055", "CORMP_0005", "CORMP_0007", "CORMP_0001", "CORMP_0002", "CORMP_0022", "CORMP_0050"))
df_change <- df_change %>% select(-1) %>% select(plot,OneHr_change,TenHr_change,HunHr_change,FineWood_change,TotalWood_change,Duff_change,Litter_change,TotalAll_change,
DuffDep_change,LittDep_change,TotDep_change,hoHrWoody_change)



write.csv(df_change, "eastside/fuels/change_pred.csv")
write.csv(vars_change, "eastside/fuels/change_vars.csv")


```




